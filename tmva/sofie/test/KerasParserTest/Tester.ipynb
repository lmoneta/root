{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107dfc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 10:55:29.736003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import ROOT\n",
    "from ROOT import TMVA\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866a8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasIdentity(layer): #Checked\n",
    "    input = layer['layerInput']\n",
    "    output = layer['layerOutput']\n",
    "    fLayerType = layer_data['layerDType']\n",
    "    fLayerInputName = input[0]\n",
    "    fLayerOutputName = output[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Identity('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Identity does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69af8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasBinary(layer): ###CHECK ABOUT FLOAT32 - IN GENERAL; also explain zeros in op creations\n",
    "    input = layer['layerInput']\n",
    "    output = layer['layerOutput']\n",
    "    fLayerType = layer_data['layerType'] \n",
    "    fLayerDType = layer_data['layerDType'] \n",
    "    fX1 = input[0]\n",
    "    fX2 = input[1]\n",
    "    fY = output[0]\n",
    "    op = None\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        if fLayerType == \"Add\":\n",
    "          op = ROOT.TMVA.Experimental.SOFIE.ROperator_BasicBinary('Add')(fX1, fX2, fY)\n",
    "        elif fLayerType == \"Subtract\":\n",
    "          op = ROOT.TMVA.Experimental.SOFIE.ROperator_BasicBinary('Sub')(fX1, fX2, fY)\n",
    "        else:\n",
    "          op = ROOT.TMVA.Experimental.SOFIE.ROperator_BasicBinary('Mul')(fX1, fX2, fY)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Identity does not yet support input type \" + fLayerDType\n",
    "        )\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc211b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasConcat(layer):\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    attributes = layer['layerAttributes']\n",
    "    input = [str(i) for i in finput]\n",
    "    output = str(foutput[0])\n",
    "    axis = int(attributes[\"axis\"])\n",
    "    op = ROOT.TMVA.Experimental.SOFIE.ROperator_Concat('float')(inputs, axis, 0,  output)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1393e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasReshape(layer): #checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible reshaping operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible reshaping operation using the SOFIE framework. Assumes layerDtype is float32.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  name, data type, and other relevant information.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Reshape: A SOFIE framework operator representing the reshaping operation.\n",
    "    \"\"\"\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    attributes = layer['layerAttributes']\n",
    "    flayername = attributes['_name']\n",
    "    fOpMode = TMVA.Experimental.SOFIE.ReshapeOpMode.Reshape\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fNameData = finput[0]\n",
    "    fNameOutput = foutput[0]\n",
    "    fNameShape = flayername + \"ReshapeAxes\"\n",
    "    op = ROOT.TMVA.Experimental.SOFIE.ROperator_Reshape('float')(fOpMode, 0, fNameData, fNameShape, fNameOutput)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf80ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasFlatten(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible flattening operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible flattening operation using the SOFIE framework.\n",
    "    Flattening is the process of converting a multi-dimensional tensor into a\n",
    "    one-dimensional tensor. Assumes layerDtype is float32.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                name, data type, and other relevant information.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Reshape: A SOFIE framework operator representing the flattening operation.\n",
    "    \"\"\"\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    attributes = layer['layerAttributes']\n",
    "    flayername = attributes['_name']\n",
    "    fOpMode = TMVA.Experimental.SOFIE.ReshapeOpMode.Flatten\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fNameData = finput[0]\n",
    "    fNameOutput = foutput[0]\n",
    "    fNameShape = flayername + \"ReshapeAxes\"\n",
    "    op = ROOT.TMVA.Experimental.SOFIE.ROperator_Reshape('float')(fOpMode, 0, fNameData, fNameShape, fNameOutput)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365fdad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasBatchNorm(layer): \n",
    "    \"\"\"\n",
    "    Create a Keras-compatible batch normalization operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a batch normalization layer and its\n",
    "    attributes and constructs a Keras-compatible batch normalization operation using\n",
    "    the SOFIE framework. Batch normalization is used to normalize the activations of\n",
    "    a neural network, typically applied after the convolutional or dense layers.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  gamma, beta, moving mean, moving variance, epsilon,\n",
    "                  momentum, data type (assumed to be float32), and other relevant information.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_BatchNormalization: A SOFIE framework operator representing the batch normalization operation.\n",
    "    \"\"\"\n",
    "        \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    attributes = layer['layerAttributes']\n",
    "    gamma = attributes[\"gamma\"]\n",
    "    beta = attributes[\"beta\"]\n",
    "    moving_mean = attributes[\"moving_mean\"]\n",
    "    moving_variance = attributes[\"moving_variance\"]\n",
    "    fLayerDType = layer[\"layerDType\"]\n",
    "    fNX = str(finput[0])\n",
    "    fNY = str(foutput[0])\n",
    "    fNScale = str(gamma.name)\n",
    "    fNB = str(beta.name)\n",
    "    fNMean = str(moving_mean.name)\n",
    "    fNVar = str(moving_variance.name)\n",
    "    epsilon = attributes[\"epsilon\"]\n",
    "    momentum = attributes[\"momentum\"]\n",
    "    op = ROOT.TMVA.Experimental.SOFIE.ROperator_BatchNormalization('float')(epsilon, momentum, 0, fNX, fNScale, fNB, fNMean, fNVar, fNY)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4144e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasActivation(layer): #irrelevant - never used\n",
    "    attributes = layer['layerAttributes']\n",
    "    activation = attributes['activation']\n",
    "    fLayerActivation = str(activation.__name__)\n",
    "    if fLayerActivation in mapKerasLayer.keys():\n",
    "        return mapKerasLayer[fLayerActivation](layer)\n",
    "    else:\n",
    "        raise Exception(\"TMVA.SOFIE - parsing keras activation layer \" + fLayerActivation + \" is not yet supported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c573fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasReLU(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible rectified linear unit (ReLU) activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible ReLU activation operation using the SOFIE framework.\n",
    "    ReLU is a popular activation function that replaces all negative values in a tensor\n",
    "    with zero, while leaving positive values unchanged.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  and data type, which must be float32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Relu: A SOFIE framework operator representing the ReLU activation operation.\n",
    "    \"\"\"\n",
    "        \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Relu('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Relu does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a678192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasSeLU(layer): #NEED TO CHECK - also check if description is correct\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible scaled exponential linear unit (SeLU) activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible SeLU activation operation using the SOFIE framework.\n",
    "    SeLU is a type of activation function that introduces self-normalizing properties\n",
    "    to the neural network, which can lead to improved training stability and convergence.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  and data type - must be float32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Selu: A SOFIE framework operator representing the SeLU activation operation.\n",
    "    \"\"\"\n",
    "        \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Selu('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Selu does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6314c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasSigmoid(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible sigmoid activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible sigmoid activation operation using the SOFIE framework.\n",
    "    Sigmoid is a commonly used activation function that maps input values to the range\n",
    "    between 0 and 1, providing a way to introduce non-linearity in neural networks.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  and data type - must be float 32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Sigmoid: A SOFIE framework operator representing the sigmoid activation operation.\n",
    "    \"\"\"\n",
    "        \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Sigmoid('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Sigmoid does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d52de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasSoftmax(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible softmax activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible softmax activation operation using the SOFIE framework.\n",
    "    Softmax is an activation function that converts input values into a probability\n",
    "    distribution, often used in the output layer of a neural network for multi-class\n",
    "    classification tasks.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  and data type - must be float32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Softmax: A SOFIE framework operator representing the softmax activation operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Softmax('float')(-1, fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Softmax does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3c8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasLeakyRelu(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible Leaky ReLU activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible Leaky ReLU activation operation using the SOFIE framework.\n",
    "    Leaky ReLU is a variation of the ReLU activation function that allows small negative\n",
    "    values to pass through, introducing non-linearity while preventing \"dying\" neurons.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  attributes, and data type - must be float 32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_LeakyRelu: A SOFIE framework operator representing the Leaky ReLU activation operation.\n",
    "    \"\"\"\n",
    "        \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    attributes = layer['layerAttributes']\n",
    "    fAlpha = float(attributes[\"alpha\"])\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_LeakyRelu('float')(fAlpha, fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator LeakyRelu does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31654c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasTanh(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible hyperbolic tangent (tanh) activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible tanh activation operation using the SOFIE framework.\n",
    "    Tanh is an activation function that squashes input values to the range between -1 and 1,\n",
    "    introducing non-linearity in neural networks.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  and data type - must be float32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Tanh: A SOFIE framework operator representing the tanh activation operation.\n",
    "    \"\"\"\n",
    "        \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Tanh('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Tanh does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4702e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasSwish(layer): #Need to switch to master, also check if description is correct\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible swish activation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible swish activation operation using the SOFIE framework.\n",
    "    Swish is an activation function that aims to combine the benefits of ReLU and sigmoid,\n",
    "    allowing some non-linearity while still keeping positive values unbounded.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  and data type.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Swish: A SOFIE framework operator representing the swish activation operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Swish('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Swish does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef049b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasPermute(layer):\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible permutation operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a layer and its attributes and\n",
    "    constructs a Keras-compatible permutation operation using the SOFIE framework.\n",
    "    Permutation is an operation that rearranges the dimensions of a tensor based on\n",
    "    specified dimensions.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  attributes, and data type - must be float32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Transpose: A SOFIE framework operator representing the permutation operation.\n",
    "    \"\"\"\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    attributes = layer['layerAttributes']\n",
    "    fAttributePermute = np.asarray(attributes[\"dims\"])\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        if len(fAttributePermute) > 0:\n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_Transpose('float')(fPermuteDims, fLayerInputName, fLayerOutputName)\n",
    "        else:    \n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_Transpose('float')(fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Transpose does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "106e7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasDense(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible dense (fully connected) layer operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a dense layer and its attributes and\n",
    "    constructs a Keras-compatible dense (fully connected) layer operation using the SOFIE framework.\n",
    "    A dense layer applies a matrix multiplication between the input tensor and weight matrix,\n",
    "    and adds a bias term.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  layer weight names, and data type - must be float 32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Gemm: A SOFIE framework operator representing the dense layer operation.\n",
    "    \"\"\"  \n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    fWeightNames = layer[\"layerWeight\"]\n",
    "    fKernelName = fWeightNames[0]\n",
    "    fBiasName = fWeightNames[1]\n",
    "    attr_alpha = 1.0\n",
    "    attr_beta  = 1.0\n",
    "    attr_transA = 0\n",
    "    attr_transB = 0\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Gemm['float'](attr_alpha, attr_beta, attr_transA, attr_transB, fLayerInputName, fKernelName, fBiasName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Gemm does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27fb9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasConv(layer): \n",
    "    \"\"\"\n",
    "    Create a Keras-compatible convolutional layer operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a convolutional layer and its attributes and\n",
    "    constructs a Keras-compatible convolutional layer operation using the SOFIE framework.\n",
    "    A convolutional layer applies a convolution operation between the input tensor and a set\n",
    "    of learnable filters (kernels).\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  data type (must be float 32), weight and bias name, kernel size, dilations, padding and strides. \n",
    "                  When padding is same (keep in the same dimensions), the padding shape is calculated.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Conv: A SOFIE framework operator representing the convolutional layer operation.\n",
    "    \"\"\"\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerDType = layer['layerDType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    attributes = layer['layerAttributes']\n",
    "    fWeightNames = layer[\"layerWeight\"]\n",
    "    fKernelName = fWeightNames[0]\n",
    "    fBiasName = fWeightNames[1]\n",
    "    fAttrDilations = attributes[\"dilation_rate\"]\n",
    "    fAttrGroup = int(attributes[\"groups\"])\n",
    "    fAttrKernelShape = attributes[\"kernel_size\"]\n",
    "    fKerasPadding = str(attributes[\"padding\"])\n",
    "    fAttrStrides = attributes[\"strides\"]\n",
    "    \n",
    "    if fKerasPadding == 'valid':\n",
    "        fAttrAutopad = 'VALID'\n",
    "    elif fKerasPadding == 'same':\n",
    "        fAttrAutopad = 'NOTSET'\n",
    "        fInputShape = attributes['_build_input_shape']\n",
    "        inputHeight = fInputShape[1]\n",
    "        inputWidth = fInputShape[2]\n",
    "        outputHeight = math.ceil(float(inputHeight) / float(fAttrStrides[0]))\n",
    "        outputWidth = math.ceil(float(inputWidth) / float(fAttrStrides[1]))\n",
    "        padding_height = max((outputHeight - 1) * fAttrStrides[0] + fAttrKernelShape[0] - inputHeight, 0)\n",
    "        padding_width = max((outputWidth - 1) * fAttrStrides[1] + fAttrKernelShape[1] - inputWidth, 0)\n",
    "        padding_top = math.floor(padding_height / 2)\n",
    "        padding_bottom = padding_height - padding_top\n",
    "        padding_left = math.floor(padding_width / 2)\n",
    "        padding_right = padding_width - padding_left\n",
    "        fAttrPads = [padding_top, padding_bottom, padding_left, padding_right]\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - RModel Keras Parser doesn't yet supports Convolution layer with padding \" + fKerasPadding\n",
    "        )\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Conv['float'](fAttrAutopad, fAttrDilations, fAttrGroup, \n",
    "                                                                  fAttrKernelShape, fAttrPads, fAttrStrides, \n",
    "                                                                  fLayerInputName, fKernelName, fBiasName, \n",
    "                                                                  fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Gemm does not yet support input type \" + fLayerDType\n",
    "        )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "157ebef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasPooling(layer): #Checked\n",
    "    \"\"\"\n",
    "    Create a Keras-compatible pooling layer operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing a pooling layer and its attributes and\n",
    "    constructs a Keras-compatible pooling layer operation using the SOFIE framework.\n",
    "    Pooling layers downsample the input tensor by selecting a representative value from\n",
    "    a group of neighboring values, either by taking the maximum or the average.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  layer type (the selection rule), the pool size, padding, strides, and data type.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_Pool: A SOFIE framework operator representing the pooling layer operation.\n",
    "    \"\"\"\n",
    "    #Set default values\n",
    "    fAttrDilations = (1,1)\n",
    "    fpads = [0,0,0,0,0,0]\n",
    "    \n",
    "    #extract attributes from layer data\n",
    "    fLayerDType = layer['layerDType']\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    fLayerType = layer['layerType']\n",
    "    fLayerInputName = finput[0]\n",
    "    fLayerOutputName = foutput[0]\n",
    "    pool_atrr = TMVA.Experimental.SOFIE.RAttributes_Pool()\n",
    "    attributes = layer['layerAttributes']\n",
    "    fAttrKernelShape = attributes[\"pool_size\"]\n",
    "    fKerasPadding = str(attributes[\"padding\"])\n",
    "    fAttrStrides = attributes[\"strides\"]\n",
    "    if fKerasPadding == 'valid':\n",
    "        fAttrAutopad = 'VALID'\n",
    "    elif fKerasPadding == 'same':\n",
    "        fAttrAutopad = 'NOTSET'\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - RModel Keras Parser doesn't yet supports Convolution layer with padding \" + fKerasPadding\n",
    "        )\n",
    "    pool_atrr.dilations = list(fAttrDilations)\n",
    "    pool_atrr.strides = list(fAttrStrides)\n",
    "    pool_atrr.pads = fpads\n",
    "    pool_atrr.kernel_shape = list(fAttrKernelShape)\n",
    "    pool_atrr.auto_pad = fAttrAutopad  \n",
    "    pool_atrr.ceil_mode = 0\n",
    "    pool_atrr.count_include_pad = 0\n",
    "    pool_atrr.storage_order = 0\n",
    "    \n",
    "    #choose pooling type\n",
    "    if fLayerType.startswith(\"Max\"):\n",
    "        PoolMode = ROOT.TMVA.Experimental.SOFIE.PoolOpMode.MaxPool\n",
    "    elif fLayerType.startswith(\"AveragePool\"):\n",
    "        PoolMode = ROOT.TMVA.Experimental.SOFIE.PoolOpMode.AveragePool\n",
    "    elif fLayerType.startswith(\"GlobalAverage\"):\n",
    "        PoolMode = ROOT.TMVA.Experimental.SOFIE.PoolOpMode.GloabalAveragePool\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator poolong does not yet support pooling type \" + fLayerType\n",
    "        )\n",
    "    \n",
    "    #create operator\n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        op = ROOT.TMVA.Experimental.SOFIE.ROperator_Pool['float'](PoolMode, pool_atrr, fLayerInputName, fLayerOutputName)\n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator Pooling does not yet support input type \" + fLayerDType\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04283093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeKerasRNN(layer): \n",
    "    \"\"\"\n",
    "    Create a Keras-compatible RNN (Recurrent Neural Network) layer operation using SOFIE framework.\n",
    "\n",
    "    This function takes a dictionary representing an RNN layer and its attributes and\n",
    "    constructs a Keras-compatible RNN layer operation using the SOFIE framework.\n",
    "    RNN layers are used to model sequences, and they maintain internal states that are\n",
    "    updated through recurrent connections.\n",
    "\n",
    "    Parameters:\n",
    "    layer (dict): A dictionary containing layer information including input, output,\n",
    "                  layer type, attributes, weights, and data type - must be float32.\n",
    "\n",
    "    Returns:\n",
    "    ROperator_RNN: A SOFIE framework operator representing the RNN layer operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract required information from the layer dictionary\n",
    "    fLayerDType = layer['layerDType']\n",
    "    finput = layer['layerInput']\n",
    "    foutput = layer['layerOutput']\n",
    "    attributes = layer['layerAttributes']\n",
    "    direction = attributes['direction']\n",
    "    hidden_size = attributes[\"hidden_size\"]\n",
    "    layout = int(attributes[\"layout\"])\n",
    "    nameX = finput[0]\n",
    "    nameY = foutput[0]\n",
    "    nameW = layer[\"layerWeight\"][0]\n",
    "    nameR = layer[\"layerWeight\"][1]\n",
    "    if len(layer[\"layerWeight\"]) > 2:\n",
    "        nameB = layer[\"layerWeight\"][2]\n",
    "    else:\n",
    "        nameB = \"\"\n",
    "    \n",
    "    # Check if the provided activation function is supported\n",
    "    fPActivation = attributes['activation']\n",
    "    if not fPActivation.__name__ in ['relu', 'sigmoid', 'tanh', 'softsign', 'softplus']: #avoiding functions with parameters\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator RNN does not yet support activation function \" + fPActivation.__name__\n",
    "        )\n",
    "    activations = [fPActivation.__name__[0].upper()+fPActivation.__name__[1:]]\n",
    "\n",
    "    #set default values\n",
    "    activation_alpha = {}\n",
    "    activation_beta = {}\n",
    "    clip = 0.0\n",
    "    nameY_h = \"\"\n",
    "    nameInitial_h = \"\"\n",
    "    name_seq_len = \"\"\n",
    "    \n",
    "    if TMVA.Experimental.SOFIE.ConvertStringToType(fLayerDType) == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "        if layer['layerType'] == \"SimpleRNN\":\n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_RNN['float'](activation_alpha, activation_beta, activations, clip, direction, hidden_size, layout, nameX, nameW, nameR, nameB, name_seq_len, nameInitial_h, nameY, nameY_h)\n",
    "        \n",
    "        elif layer['layerType'] == \"GRU\":\n",
    "            #an additional activation function is required, given by the user\n",
    "            activations.insert(0,attributes['recurrent_activation'])\n",
    "            \n",
    "            #new variable needed:\n",
    "            linear_before_reset = 1 #SOLVE - in case when there is only 1 bias it's zero\n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_GRU['float'](activation_alpha, activation_beta, activations, clip, direction, hidden_size, layout, linear_before_reset, nameX, nameW, nameR, nameB, name_seq_len, nameInitial_h, nameY, nameY_h)\n",
    "        \n",
    "        elif layer['layerType'] == \"LSTM\":\n",
    "            #an additional activation function is required, the first given by the user, the second set to tanh as default\n",
    "            fPRecurrentActivation = attributes['recurrent_activation']\n",
    "            if not fPActivation.__name__ in ['relu', 'sigmoid', 'tanh', 'softsign', 'softplus']: #avoiding functions with parameters\n",
    "                raise RuntimeError(\n",
    "                    \"TMVA::SOFIE - Unsupported - Operator RNN does not yet support recurrent activation function \" + fPActivation.__name__\n",
    "                )\n",
    "            fPRecurrentActivationName = fPRecurrentActivation.__name__[0].upper()+fPRecurrentActivation.__name__[1:]\n",
    "            activations.insert(0,fPRecurrentActivationName)\n",
    "            activations.insert(2,'Tanh')\n",
    "                    \n",
    "            #new variables needed:\n",
    "            input_forget = 0\n",
    "            nameInitial_c = \"\"\n",
    "            nameP = \"\" #No peephole connections in keras LSTM model\n",
    "            nameY_c = \"\"\n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_LSTM['float'](activation_alpha, activation_beta, activations, clip, direction, hidden_size, input_forget, layout, nameX, nameW, nameR, nameB, name_seq_len, nameInitial_h, nameInitial_c, nameP, nameY, nameY_h, nameY_c)\n",
    "        \n",
    "        else: \n",
    "            raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator RNN does not yet support operator type \" + layer['layerType']\n",
    "        ) \n",
    "        return op\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            \"TMVA::SOFIE - Unsupported - Operator RNN does not yet support input type \" + fLayerDType\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f719a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set global dictionaries, mapping layers to corresponding functions that create their ROperator instances\n",
    "mapKerasLayer = {\"Activation\": MakeKerasActivation,\n",
    "                 \"Permute\": MakeKerasPermute,\n",
    "                 \"BatchNormalization\": MakeKerasBatchNorm,\n",
    "                 \"Reshape\": MakeKerasReshape,\n",
    "                 \"Flatten\": MakeKerasFlatten,\n",
    "                 \"Concatenate\": MakeKerasConcat,\n",
    "                 \"swish\": MakeKerasSwish,\n",
    "                 \"Add\": MakeKerasBinary,\n",
    "                 \"Subtract\": MakeKerasBinary,\n",
    "                 \"Multiply\": MakeKerasBinary,\n",
    "                 \"Softmax\": MakeKerasSoftmax,\n",
    "                 \"tanh\": MakeKerasTanh,\n",
    "                 \"Identity\": MakeKerasIdentity,\n",
    "                 \"Dropout\": MakeKerasIdentity,\n",
    "                 \"ReLU\": MakeKerasReLU,\n",
    "                 \"relu\": MakeKerasReLU,\n",
    "                 \"selu\": MakeKerasSeLU,\n",
    "                 \"sigmoid\": MakeKerasSigmoid,\n",
    "                 \"LeakyReLU\": MakeKerasLeakyRelu, \n",
    "                 \"softmax\": MakeKerasSoftmax, \n",
    "                 \"MaxPooling2D\": MakeKerasPooling,\n",
    "                 \"SimpleRNN\": MakeKerasRNN,\n",
    "                 \"GRU\": MakeKerasRNN,\n",
    "                 \"LSTM\": MakeKerasRNN,\n",
    "                 }\n",
    "\n",
    "mapKerasLayerWithActivation = {\"Dense\": MakeKerasDense,\"Conv2D\": MakeKerasConv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69d892db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer_into_RModel(rmodel, layer_data):\n",
    "    \"\"\"\n",
    "    Add a Keras layer operation to an existing RModel using the SOFIE framework.\n",
    "\n",
    "    This function takes an existing RModel and a dictionary representing a Keras layer\n",
    "    and its attributes, and adds the corresponding layer operation to the RModel using\n",
    "    the SOFIE framework. The function supports various types of Keras layers, including\n",
    "    those with or without activation functions.\n",
    "\n",
    "    Parameters:\n",
    "    rmodel (RModel): An existing RModel to which the layer operation will be added.\n",
    "    layer_data (dict): A dictionary containing layer information including type,\n",
    "                      attributes, input, output, and layer data type.\n",
    "\n",
    "    Returns:\n",
    "    RModel: The updated RModel after adding the layer operation.\n",
    "\n",
    "    Raises exception: If the provided layer type or activation function is not supported.\n",
    "    \"\"\"\n",
    "    \n",
    "    fLayerType = layer_data['layerType']\n",
    "    \n",
    "    #reshape and flatten layers don't have weights, but they are needed inside the list of initialized tensor list in the Rmodel\n",
    "    if fLayerType == \"Reshape\" or fLayerType == \"Flatten\":\n",
    "        Attributes = layer_data['layerAttributes']\n",
    "        LayerName = Attributes['_name']\n",
    "        if fLayerType == \"Reshape\":\n",
    "            TargetShape = np.asarray(Attributes['target_shape']).astype(\"int\")\n",
    "            TargetShape = np.insert(TargetShape,0,0)\n",
    "        else:\n",
    "            input_shape = layer_data['layerAttributes']['_build_input_shape']\n",
    "            TargetShape = [ROOT.TMVA.Experimental.SOFIE.ConvertShapeToLength(input_shape[1:])]\n",
    "            TargetShape = np.asarray(TargetShape)\n",
    "        \n",
    "        #since the AddInitializedTensor method in RModel requires unique pointer, we call a helper function in c++ that does the conversion from a regular pointer to unique one in c++\n",
    "        rmodel.AddInitializedTensorFromPy['long'](LayerName+\"ReshapeAxes\",ROOT.TMVA.Experimental.SOFIE.ETensorType.INT64,[len(TargetShape)], TargetShape)\n",
    "    \n",
    "    #These layers only have one operator - excluding the recurrent layers, in which the activation function(s) are included in the recurrent operator\n",
    "    if fLayerType in mapKerasLayer.keys():\n",
    "        Attribues = layer_data['layerAttributes']\n",
    "        inputs = layer_data['layerInput']\n",
    "        outputs = layer_data['layerOutput']\n",
    "        LayerName = Attribues['_name']\n",
    "        \n",
    "        #Pooling layers in keras by default assume the channels dimension is the last one, \n",
    "        #while in onnx (and the RModel) it is the first one (other than batch size), \n",
    "        #so a transpose is needed before and after the pooling. ADD IF CHANNELS LAST\n",
    "        if fLayerType == 'MaxPooling2D':\n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_Transpose('float')([0,3,1,2], inputs[0], LayerName+\"PreTrans\")\n",
    "            rmodel.AddOperatorFromPy(op)\n",
    "            inputs[0] = LayerName+\"PreTrans\"\n",
    "            layer_data[\"layerInput\"] = inputs\n",
    "            outputs[0] = LayerName+fLayerType\n",
    "            layer_data['layerOutput'] = outputs\n",
    "        rmodel.AddOperatorFromPy(mapKerasLayer[fLayerType](layer_data))\n",
    "        if fLayerType == 'MaxPooling2D':\n",
    "            op = ROOT.TMVA.Experimental.SOFIE.ROperator_Transpose('float')([0,2,3,1], LayerName+fLayerType, LayerName+\"PostTrans\")\n",
    "            rmodel.AddOperatorFromPy(op)\n",
    "        return rmodel\n",
    "    \n",
    "    #These layers require two operators - dense/conv and their activation funciton\n",
    "    elif fLayerType in mapKerasLayerWithActivation.keys():\n",
    "        Attribues = layer_data['layerAttributes']\n",
    "        LayerName = Attribues['_name']\n",
    "        fPActivation = Attribues['activation']\n",
    "        LayerActivation = fPActivation.__name__\n",
    "        if LayerActivation in ['selu', 'sigmoid']:\n",
    "            rmodel.AddNeededStdLib(\"cmath\")\n",
    "        \n",
    "        #if there is an activation function after the layer\n",
    "        if LayerActivation != 'linear':\n",
    "            outputs = layer_data['layerOutput']\n",
    "            inputs = layer_data['layerInput']\n",
    "            fActivationLayerOutput = outputs[0]\n",
    "            \n",
    "            #like pooling, convolutional layer from keras requires transpose before and after to match the onnx format \n",
    "            # ADD IF CHANNELS LAST\n",
    "            if fLayerType == 'Conv2D':\n",
    "                op = ROOT.TMVA.Experimental.SOFIE.ROperator_Transpose('float')([0,3,1,2], inputs[0], LayerName+\"PreTrans\")\n",
    "                rmodel.AddOperatorFromPy(op)\n",
    "                inputs[0] = LayerName+\"PreTrans\"\n",
    "                layer_data[\"layerInput\"] = inputs\n",
    "            outputs[0] = LayerName+fLayerType\n",
    "            layer_data['layerOutput'] = outputs\n",
    "            op = mapKerasLayerWithActivation[fLayerType](layer_data)\n",
    "            rmodel.AddOperatorFromPy(op)\n",
    "            Activation_layer_input = LayerName+fLayerType\n",
    "            if fLayerType == 'Conv2D':\n",
    "                op = ROOT.TMVA.Experimental.SOFIE.ROperator_Transpose('float')([0,2,3,1], LayerName+fLayerType, LayerName+\"PostTrans\")\n",
    "                rmodel.AddOperatorFromPy(op)\n",
    "                Activation_layer_input = LayerName + \"PostTrans\"\n",
    "            \n",
    "            #Adding the activation function\n",
    "            inputs[0] = Activation_layer_input\n",
    "            outputs[0] = fActivationLayerOutput\n",
    "            layer_data['layerInput'] = inputs\n",
    "            layer_data['layerOutput'] = outputs\n",
    "            if not LayerActivation in mapKerasLayer.keys():\n",
    "                raise Exception(\"TMVA.SOFIE - parsing keras activation function \" + LayerActivation + \" is not yet supported\")\n",
    "            rmodel.AddOperatorFromPy(mapKerasLayer[LayerActivation](layer_data))\n",
    "            \n",
    "        else: #there is a bug here if it is conv and the activation is linear, need to add transpose before and after\n",
    "            rmodel.AddOperatorFromPy(mapKerasLayerWithActivation[fLayerType](layer_data))\n",
    "        return rmodel\n",
    "    else:\n",
    "        raise Exception(\"TMVA.SOFIE - parsing keras layer \" + fLayerType + \" is not yet supported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "034a9250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Keras_Parser_into_RModel(filename):\n",
    "    #Check if file exists\n",
    "    if not os.path.exists(filename):\n",
    "        raise RuntimeError(\"Model file {} not found!\".format(filename))\n",
    "        \n",
    "    #load model\n",
    "    keras_model = keras.models.load_model(modelFile)\n",
    "    keras_model.load_weights(modelFile)\n",
    "    \n",
    "    #create new RModel object\n",
    "    sep = '/'\n",
    "    if os.name == 'nt':\n",
    "        sep = '\\\\'\n",
    "    \n",
    "    isep = filename.rfind(sep)\n",
    "    filename_nodir = filename\n",
    "    if isep != -1:\n",
    "        filename_nodir = filename[isep+1:]\n",
    "    \n",
    "    ttime = time.time()\n",
    "    gmt_time = time.gmtime(ttime)\n",
    "    parsetime = time.asctime(gmt_time)\n",
    "    \n",
    "    rmodel = ROOT.TMVA.Experimental.SOFIE.RModel.RModel(filename_nodir, parsetime)\n",
    "    \n",
    "    #iterate over the layers and add them to the RModel\n",
    "    for layer in keras_model.layers:\n",
    "        layer_data={}\n",
    "        layer_data['layerType']=layer.__class__.__name__\n",
    "        layer_data['layerAttributes']=layer.__dict__\n",
    "        layer_data['layerInput']=[x.name for x in layer.input] if isinstance(layer.input,list) else [layer.input.name]\n",
    "        layer_data['layerOutput']=[x.name for x in layer.output] if isinstance(layer.output,list) else [layer.output.name]\n",
    "        layer_data['layerDType']=layer.dtype\n",
    "        layer_data['layerWeight']=[x.name for x in layer.weights]\n",
    "        \n",
    "        #for recurrent type layers we need to extract additional unique information\n",
    "        if layer_data['layerType'] in [\"SimpleRNN\", \"LSTM\", \"GRU\"]:\n",
    "            layer_data['layerAttributes']['activation'] = layer.activation\n",
    "            layer_data['layerAttributes']['direction'] = 'backward' if layer.go_backwards else 'forward'\n",
    "            layer_data['layerAttributes'][\"units\"] = layer.units\n",
    "            layer_data['layerAttributes'][\"layout\"] = layer.input.shape[0] is None\n",
    "            layer_data['layerAttributes'][\"hidden_size\"] = layer.output.shape[-1]\n",
    "            \n",
    "            #for GRU and LSTM we need to extract an additional activation function\n",
    "            if layer_data['layerType'] != \"SimpleRNN\": \n",
    "                layer_data['layerAttributes']['recurrent_activation'] = layer.recurrent_activation\n",
    "                       \n",
    "        if layer_data['layerInput'][0].startswith('max_pooling2d'):\n",
    "            pooling_layer_name = layer_data['layerInput'][0].split('/')[0]\n",
    "            layer_data['layerInput'][0] = pooling_layer_name + 'PostTrans'\n",
    "        \n",
    "        fLayerType = layer_data['layerType']\n",
    "        #Ignoring the input layer for models built using Keras Functional API\n",
    "        #NEED TO TEST KERAS FUNCTIONAL API\n",
    "        if(fLayerType == \"InputLayer\"):\n",
    "            continue;\n",
    "\n",
    "        #Adding any required routines depending on the Layer types for generating inference code.\n",
    "        elif (fLayerType == \"Dense\"):\n",
    "            rmodel.AddBlasRoutines({\"Gemm\", \"Gemv\"})\n",
    "        elif (fLayerType == \"BatchNormalization\"):\n",
    "            rmodel.AddBlasRoutines({\"Copy\", \"Axpy\"})\n",
    "        elif (fLayerType == \"Conv1D\" or fLayerType == \"Conv2D\" or fLayerType == \"Conv3D\"):\n",
    "            rmodel.AddBlasRoutines({\"Gemm\", \"Axpy\"})\n",
    "        rmodel = add_layer_into_RModel(rmodel, layer_data)\n",
    "\n",
    "    # Extracting model's weights\n",
    "    weight = []\n",
    "    for idx in range(len(keras_model.get_weights())):\n",
    "        weightProp = {}\n",
    "        weightProp['name'] = keras_model.weights[idx].name\n",
    "        weightProp['dtype'] = keras_model.get_weights()[idx].dtype.name\n",
    "        if 'conv' in keras_model.weights[idx].name and keras_model.weights[idx].shape.ndims == 4:\n",
    "            weightProp['value'] = keras_model.get_weights()[idx].transpose((3, 2, 0, 1)).copy()\n",
    "        else:\n",
    "            weightProp['value'] = keras_model.get_weights()[idx]\n",
    "        weight.append(weightProp)\n",
    "\n",
    "    # Traversing through all the Weight tensors\n",
    "    for weightIter in range(len(weight)):\n",
    "        fWeightTensor = weight[weightIter]\n",
    "        fWeightName = fWeightTensor['name']\n",
    "        fWeightDType = TMVA.Experimental.SOFIE.ConvertStringToType(fWeightTensor['dtype'])\n",
    "        fWeightTensorValue = fWeightTensor['value']\n",
    "        fWeightTensorSize = 1\n",
    "        fWeightTensorShape = []\n",
    "        \n",
    "        #IS IT BATCH SIZE? CHECK ONNX\n",
    "        if fWeightName.startswith(\"simple_rnn\") or fWeightName.startswith(\"lstm\") or (fWeightName.startswith(\"gru\") and not 'bias' in fWeightName):\n",
    "            fWeightTensorShape.append(1)\n",
    "        \n",
    "        # Building the shape vector and finding the tensor size\n",
    "        for j in range(len(fWeightTensorValue.shape)):\n",
    "            fWeightTensorShape.append(fWeightTensorValue.shape[j])\n",
    "            fWeightTensorSize *= fWeightTensorValue.shape[j]\n",
    "        \n",
    "        if fWeightDType == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "            fWeightArray = fWeightTensorValue\n",
    "            \n",
    "            #weights conversion format between keras and onnx for lstm: the order of the different elements (input, output, forget, cell) inside the vector/matrix is different\n",
    "            if fWeightName.startswith(\"lstm\"):\n",
    "                if 'kernel' in fWeightName:\n",
    "                    units = int(fWeightArray.shape[1]/4)\n",
    "                    print(\"units = {}\".format(units))\n",
    "                    print(fWeightArray)\n",
    "                    W_i = fWeightArray[:, :units].copy()\n",
    "                    W_f = fWeightArray[:, units: units * 2].copy()\n",
    "                    W_c = fWeightArray[:, units * 2: units * 3].copy()\n",
    "                    W_o = fWeightArray[:, units * 3:].copy()\n",
    "                    fWeightArray[:, units: units * 2] = W_o\n",
    "                    fWeightArray[:, units * 2: units * 3] = W_f\n",
    "                    fWeightArray[:, units * 3:] = W_c\n",
    "                else: #bias\n",
    "                    units = int(fWeightArray.shape[0]/4)\n",
    "                    #print(\"units = {}\".format(units))\n",
    "                    #print(fWeightArray)\n",
    "                    W_i = fWeightArray[:units].copy()\n",
    "                    W_f = fWeightArray[units: units * 2].copy()\n",
    "                    W_c = fWeightArray[units * 2: units * 3].copy()\n",
    "                    W_o = fWeightArray[units * 3:].copy()\n",
    "                    fWeightArray[units: units * 2] = W_o\n",
    "                    fWeightArray[units * 2: units * 3] = W_f\n",
    "                    fWeightArray[units * 3:] = W_c\n",
    "           \n",
    "            #need to make specific adjustments for recurrent weights and biases\n",
    "            if (fWeightName.startswith(\"simple_rnn\") or fWeightName.startswith(\"lstm\") or fWeightName.startswith(\"gru\")):\n",
    "                #reshaping weight matrices for recurrent layers due to keras-onnx inconsistencies\n",
    "                if 'kernel' in fWeightName:\n",
    "                    fWeightArray = np.transpose(fWeightArray)\n",
    "                    fWeightTensorShape[1], fWeightTensorShape[2] = fWeightTensorShape[2], fWeightTensorShape[1]\n",
    "                \n",
    "                fData = fWeightArray.flatten()\n",
    "                \n",
    "                #the recurrent bias and the cell bias can be the same, in which case we need to add a vector of zeros for the recurrent bias\n",
    "                if 'bias' in fWeightName and len(fData.shape) == 1:\n",
    "                    fWeightTensorShape[1] *= 2\n",
    "                    fRbias = fData.copy()*0\n",
    "                    fData = np.concatenate((fData,fRbias))\n",
    "\n",
    "            else:\n",
    "                fData = fWeightArray.flatten()\n",
    "                \n",
    "            rmodel.AddInitializedTensorFromPy['float'](fWeightName, ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT, fWeightTensorShape, fData)\n",
    "        else:\n",
    "            raise TypeError(\"Type error: TMVA SOFIE does not yet support data layer type: \" + fWeightDType)\n",
    "    \n",
    "    # Extracting input tensor info\n",
    "    fPInputs = keras_model.input_names\n",
    "    fPInputShape = keras_model.input_shape if isinstance(keras_model.input_shape, list) else [keras_model.input_shape]\n",
    "    fPInputDType = []\n",
    "    for idx in range(len(keras_model.inputs)):\n",
    "        fPInputDType.append(keras_model.inputs[idx].dtype.__str__()[9:-2])\n",
    "    \n",
    "    if len(fPInputShape) == 1:\n",
    "        fInputName = fPInputs[0]\n",
    "        fInputDType = TMVA.Experimental.SOFIE.ConvertStringToType(fPInputDType[0])\n",
    "        if fInputDType == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "            if fPInputShape[0][0] is None or fPInputShape[0][0] <= 0:\n",
    "                fPInputShape = list(fPInputShape[0])\n",
    "                fPInputShape[0] = 1\n",
    "            rmodel.AddInputTensorInfo(fInputName, ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT, fPInputShape)\n",
    "            rmodel.AddInputTensorName(fInputName) \n",
    "        else:\n",
    "            raise TypeError(\"Type error: TMVA SOFIE does not yet support data type \"+TMVA.Experimental.SOFIE.ConvertStringToType(fInputDType))\n",
    "    else:\n",
    "         #Iterating through multiple input tensors\n",
    "        for fInputName, fInputDType, fInputShapeTuple in zip(fPInputs, fPInputDType, fPInputShape):\n",
    "            fInputDType = TMVA.Experimental.SOFIE.ConvertStringToType(fInputDType)\n",
    "            if fInputDType == ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT:\n",
    "                if fInputShapeTuple[0] is None or fInputShapeTuple[0] <= 0:\n",
    "                    fInputShapeTuple = list(fInputShapeTuple)\n",
    "                    fInputShapeTuple[0] = 1\n",
    "                    print(\"Model does not have a defined batch size. Assuming it is 1 - input shape: \", fInputShapeTuple)\n",
    "                rmodel.AddInputTensorInfo(fInputName, ROOT.TMVA.Experimental.SOFIE.ETensorType.FLOAT, fInputShapeTuple)\n",
    "                rmodel.AddInputTensorName(fInputName)\n",
    "            else:\n",
    "                raise TypeError(\"Type error: TMVA SOFIE does not yet support data type \"+TMVA.Experimental.SOFIE.ConvertStringToType(fInputDType))             \n",
    "        \n",
    "    # Adding OutputTensorInfos\n",
    "    outputNames = []\n",
    "    for layerName in keras_model.output_names:\n",
    "        outputNames.append(keras_model.get_layer(layerName).output.name)\n",
    "    rmodel.AddOutputTensorNameList(outputNames)\n",
    "    print(\"created RModel\")\n",
    "    return rmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5214c463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Relutest.h5 in the header  Relutest.hxx\n",
      "compiling SOFIE model  Relutest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_ReluIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 10:55:39.354546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "modelFile = \"Relutest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Relutest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce452c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Selutest.h5 in the header  Selutest.hxx\n",
      "compiling SOFIE model  Selutest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_SeluIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"Selutest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Selutest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef20d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Tanhtest.h5 in the header  Tanhtest.hxx\n",
      "compiling SOFIE model  Tanhtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_TanhIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"Tanhtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Tanhtest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd316a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  LeakyRelutest.h5 in the header  LeakyRelutest.hxx\n",
      "compiling SOFIE model  LeakyRelutest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_LeakyReluIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"LeakyRelutest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_LeakyRelutest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b08328a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Sigmoidtest.h5 in the header  Sigmoidtest.hxx\n",
      "compiling SOFIE model  Sigmoidtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_SigmoidIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"Sigmoidtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Sigmoidtest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efb934aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Softmaxtest.h5 in the header  Softmaxtest.hxx\n",
      "compiling SOFIE model  Softmaxtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_SoftmaxIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"Softmaxtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Softmaxtest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a6b1e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  MLPtest.h5 in the header  MLPtest.hxx\n",
      "compiling SOFIE model  MLPtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_SeluIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_TanhIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_SigmoidIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_ReluIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_SigmoidIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"MLPtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_MLPtest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "648b43da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  BatchNormalizationtest.h5 in the header  BatchNormalizationtest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE28ROperator_BatchNormalizationIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"BatchNormalizationtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_BatchNormalizationtest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b05f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  CNNtest.h5 in the header  CNNtest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "kernel shape { 2 , 2 }\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 16 , 16 , 1 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "reshapeReshape0\n",
      "transpose fAttrPerm0 3 1 2\n",
      "\n",
      "transpose input shape1 16 16 1\n",
      "transpose output shape1 1 16 16\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_ConvIfEE\n",
      "Elements of the input vector:\n",
      "1 1 16 16 \n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "conv2dConv2D\n",
      "transpose fAttrPerm0 2 3 1\n",
      "\n",
      "transpose input shape1 10 16 16\n",
      "transpose output shape1 16 16 10\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_ReluIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "conv2dRelu0\n",
      "transpose fAttrPerm0 3 1 2\n",
      "\n",
      "transpose input shape1 16 16 10\n",
      "transpose output shape1 10 16 16\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_PoolIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "maxpooling2dMaxPooling2D\n",
      "transpose fAttrPerm0 2 3 1\n",
      "\n",
      "transpose input shape1 10 8 8\n",
      "transpose output shape1 8 8 10\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 640 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_TanhIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_SigmoidIfEE\n",
      "called intermidiatefinished operatorsinitilizedoW = 16 oH = 16oD = 1\n"
     ]
    }
   ],
   "source": [
    "modelFile = \"CNNtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_CNNtest.Session()\n",
    "input_test = np.ones((1,256), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da02eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Convtest.h5 in the header  Convtest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 , 1 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "reshape2Reshape0\n",
      "transpose fAttrPerm0 3 1 2\n",
      "\n",
      "transpose input shape1 2 2 1\n",
      "transpose output shape1 1 2 2\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_ConvIfEE\n",
      "Elements of the input vector:\n",
      "1 1 2 2 \n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "conv2d2Conv2D\n",
      "transpose fAttrPerm0 2 3 1\n",
      "\n",
      "transpose input shape1 1 1 3\n",
      "transpose output shape1 1 3 1\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_SigmoidIfEE\n",
      "called intermidiatefinished operatorsinitilizedoW = 3 oH = 1oD = 1\n"
     ]
    }
   ],
   "source": [
    "modelFile = \"Convtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Convtest.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f14a03db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  MaxPooltest.h5 in the header  MaxPooltest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "kernel shape { 2 , 2 }\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 , 1 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "reshape5Reshape0\n",
      "transpose fAttrPerm0 3 1 2\n",
      "\n",
      "transpose input shape1 2 2 1\n",
      "transpose output shape1 1 2 2\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_PoolIfEE\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE19ROperator_TransposeIfEE\n",
      "maxpooling2d2MaxPooling2D\n",
      "transpose fAttrPerm0 2 3 1\n",
      "\n",
      "transpose input shape1 1 1 1\n",
      "transpose output shape1 1 1 1\n",
      "called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 1 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_GemmIfEE\n",
      "called intermidiatecalled intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_TanhIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"MaxPooltest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_MaxPooltest.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "febac839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RModel\n",
      "Generating inference code for the Keras model from  Flattentest.h5 in the header  Flattentest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 , 1 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 4 }called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"Flattentest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Flattentest.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d417b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "created RModel\n",
      "Generating inference code for the Keras model from  GRUtest.h5 in the header  GRUtest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE13ROperator_GRUIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"GRUtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_GRUtest.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d182c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "created RModel\n",
      "Generating inference code for the Keras model from  GRUtestWithBias.h5 in the header  GRUtestWithBias.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE13ROperator_GRUIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"GRUtestWithBias.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_GRUtestWithBias.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b57fd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['Sigmoid', 'Tanh', 'Tanh']\n",
      "units = 3\n",
      "[[ 0.26783913 -0.38688368  0.5643282   0.13166183 -0.07244605 -0.64679545\n",
      "  -0.19337747 -0.39189202  0.44501936  0.1427446   0.6533164   0.58202267]\n",
      " [-0.47489387  0.4988736  -0.18503693  0.19428462 -0.10970682  0.5229168\n",
      "   0.18104374 -0.24045089 -0.18928796 -0.07183313  0.30804825  0.03168583]]\n",
      "units = 3\n",
      "[[ 0.13411438 -0.41057774  0.19926903  0.28373468  0.4937415   0.22720744\n",
      "   0.2932028   0.3760723   0.03629123 -0.3049403   0.17142445  0.21617477]\n",
      " [-0.24340835 -0.2369854  -0.09374416  0.03825668 -0.2696954   0.08172181\n",
      "  -0.6508013   0.2134273  -0.2155317  -0.44375497 -0.10091524  0.26883966]\n",
      " [-0.41502652 -0.28477955 -0.23169267 -0.1553243  -0.33162177 -0.2608538\n",
      "   0.37693858  0.46355975  0.25802857  0.21111429 -0.05007693  0.14213687]]\n",
      "created RModel\n",
      "Generating inference code for the Keras model from  LSTMtestWithBias.h5 in the header  LSTMtestWithBias.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_LSTMIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"LSTMtestWithBias.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_LSTMtestWithBias.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "257eb151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['Sigmoid', 'Tanh', 'Tanh']\n",
      "units = 3\n",
      "[[ 0.19947463  0.09613985  0.51020825  0.40017605  0.61083114 -0.6033211\n",
      "  -0.24632642  0.02559096 -0.16021916 -0.15469247 -0.41483444  0.28665793]\n",
      " [ 0.05244327  0.22595686 -0.52477694  0.5990974   0.32021672  0.3718195\n",
      "   0.2150839   0.5866984  -0.24028108 -0.524948   -0.5695894  -0.25812244]]\n",
      "units = 3\n",
      "[[-0.12887514 -0.15723127 -0.53975976  0.05767192 -0.26313722 -0.11784092\n",
      "  -0.40979493  0.32428595  0.49482974  0.02542116 -0.22231646 -0.11337657]\n",
      " [ 0.46751258  0.00470898  0.23244767  0.29808924 -0.05700614  0.5897542\n",
      "  -0.33070362  0.01808098  0.13594328 -0.17507811  0.08917926 -0.34739476]\n",
      " [-0.50239605  0.10933484  0.01776595 -0.06194825  0.16853844  0.14763957\n",
      "  -0.3424148  -0.70896864  0.21470068 -0.0947246  -0.01963194 -0.07713211]]\n",
      "created RModel\n",
      "Generating inference code for the Keras model from  LSTMtest.h5 in the header  LSTMtest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE14ROperator_LSTMIfEE\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"LSTMtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_LSTMtest.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfa7aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "created RModel\n",
      "Generating inference code for the Keras model from  SimpleRNNtestWithBias.h5 in the header  SimpleRNNtestWithBias.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE13ROperator_RNNIfEE\n",
      "1\t1\n",
      "1\t1\n",
      "0\n",
      "2\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"SimpleRNNtestWithBias.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_SimpleRNNtestWithBias.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79431739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "created RModel\n",
      "Generating inference code for the Keras model from  SimpleRNNtest.h5 in the header  SimpleRNNtest.hxx\n",
      "compiling SOFIE model  BatchNormalizationtest\n",
      "fraction of equal elements in the results vector = 100.0%\n",
      "begin initializebegin input tensorsadded input tensorsfinished weight file\n",
      "initialize operator  N4TMVA12Experimental5SOFIE17ROperator_ReshapeIfEE\n",
      "reshape output shape: { 1 , 2 , 2 }called intermidiate\n",
      "initialize operator  N4TMVA12Experimental5SOFIE13ROperator_RNNIfEE\n",
      "0\t0\n",
      "0\t0\n",
      "0\n",
      "2\n",
      "called intermidiatefinished operatorsinitilized"
     ]
    }
   ],
   "source": [
    "modelFile = \"SimpleRNNtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_SimpleRNNtest.Session()\n",
    "input_test = np.ones((1,4), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7537bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodelFile = \"Swishtest.h5\"\\nrmodel = Keras_Parser_into_RModel(modelFile)\\ngeneratedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\\nprint(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\\nrmodel.Generate()\\nrmodel.OutputGenerated(generatedHeaderFile)\\nmodelName = modelFile.replace(\".h5\",\"\")\\nprint(\"compiling SOFIE model \", modelName)\\nret = ROOT.gInterpreter.Declare(\\'#include \"\\' + generatedHeaderFile + \\'\"\\')\\nif not ret:\\n    print(\"Error compiling header file \", generatedHeaderFile)\\n    exit()\\nsession = ROOT.TMVA_SOFIE_Swishtest.Session()\\ninput_test = np.ones((1,7), dtype = \\'float32\\')\\nresult = session.infer(input_test)\\nkeras_model = keras.models.load_model(modelFile)\\nkeras_model.load_weights(modelFile)\\nkeras_result = keras_model(input_test)\\n#We lower the precision because keras provides slightly better precision\\naccuracy = np.mean(np.asarray(result).astype(\\'float16\\') == np.asarray(keras_result).astype(\\'float16\\'))\\nprint(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) \\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "modelFile = \"Swishtest.h5\"\n",
    "rmodel = Keras_Parser_into_RModel(modelFile)\n",
    "generatedHeaderFile = modelFile.replace(\".h5\",\".hxx\")\n",
    "print(\"Generating inference code for the Keras model from \",modelFile,\"in the header \", generatedHeaderFile)\n",
    "rmodel.Generate()\n",
    "rmodel.OutputGenerated(generatedHeaderFile)\n",
    "modelName = modelFile.replace(\".h5\",\"\")\n",
    "print(\"compiling SOFIE model \", modelName)\n",
    "ret = ROOT.gInterpreter.Declare('#include \"' + generatedHeaderFile + '\"')\n",
    "if not ret:\n",
    "    print(\"Error compiling header file \", generatedHeaderFile)\n",
    "    exit()\n",
    "session = ROOT.TMVA_SOFIE_Swishtest.Session()\n",
    "input_test = np.ones((1,7), dtype = 'float32')\n",
    "result = session.infer(input_test)\n",
    "keras_model = keras.models.load_model(modelFile)\n",
    "keras_model.load_weights(modelFile)\n",
    "keras_result = keras_model(input_test)\n",
    "#We lower the precision because keras provides slightly better precision\n",
    "accuracy = np.mean(np.asarray(result).astype('float16') == np.asarray(keras_result).astype('float16'))\n",
    "print(\"fraction of equal elements in the results vector = {}%\".format(100*accuracy)) \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
